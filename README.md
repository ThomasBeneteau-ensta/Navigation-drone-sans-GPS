## ğŸ§­ NAVigation par Reconnaissance de l'Environnement et Cartographie (NAVREC)
<img src="https://github.com/user-attachments/assets/3783ee5e-a382-43fc-86ac-b3f2c6216c01" width="50%" height="50%">

> projet de 3Ã¨me annÃ©e : SystÃ¨mes embarquÃ©es [ENSTA Bretagne](https://www.ensta-bretagne.fr/fr)


## ğŸ“Œ Description
<p align="justify">
Ce projet permet de faciliter le dÃ©veloppement d'un algorythme de gÃ©olocalisation d'un quadricopter par reconnaissance du paysage vu du ciel, et comparaison Ã  une carte vectorielle en mÃ©moire. 
On vient pour cela simuler un drone qui cherche Ã  suivre une navigation prÃ©parÃ©e Ã  l'avance, et on vient utiliser des images satellites de l'IGN (20cm/pixel) pour simuler une prise d'image par la camÃ©ra du drone, pointÃ©e sur le sol.
</p>

<p align="justify">

</p>

Il utilise :
- ğŸ”¹ **Langage principal** : `Python`
- ğŸ”¹ **Framework utilisÃ©** : `OSMnx`
- ğŸ”¹ **Base de donnÃ©es** : `BD ORTHOÂ®`

## ğŸ“† Organisation du projet
Les tÃ¢ches ont Ã©tÃ© divisÃ©s de tel maniÃ¨re que Robin c'est occupÃ© de la partie simulateur de drone, images satellites et traitement d'image, alors que Thomas c'est occupÃ© de la partie carte vectorielle, OpenStreetMap et algorithme de comparaison objets dÃ©tectÃ©s / carte vectorielle connue.

<img src="https://mermaid.ink/img/pako:eNptVEtu2zAQvcqAi7oF5ECW9bN2RY1k5SSIiwItvKHFic2WIlWKcu0GOUCPEvQYvlhHlqUqHxoyKHHee_PjPLDcCGQZ23Dt3EoDLcEdXhpbcAfwldZ4sRjP5-2Zk04htOvGEkhW3Emj4daa7-jgmu_kpv1ScV3B1e2yBeI-V7XAqtn_QvyBWlTtSftfYX5CfeE51zmez7o3EAjX5vhXQQacDHfoQW6l82A38SDwg3A8CcbB1IOJL1b6OeWdWcvzJ4v5Fi09IAu-IV7yHpWSjrb_mXnH6c9azki08IJypbqIhTUah6iAnnuH9ow_YwTuUJmyxAK1A1M7qUCMcF8qI92ZidRf-0PZlNodnza2tRooTXsl0px2SgtZIfAaSmtKiyBqaGo7xIVv5KpBkg52Mjcl6qWziG7By1fp5lEvHQ4S4ywnn08RitEplKFs3GOigagwed0gXkWX9ObxwLy0x6fqLfO0N0_eLP_nrSn4uZ_mzzRzbh1CdSjWRsmf9dDn9YsW6Mt513eQGJ2KWcH7m-VC7z1YbnmJ6vBhSNP3xHrYE58oltaFd1DQHSpr1XUCXKGZc8cvLS9wQNSXvKEMO6LjHwqlQakRxQJjwMpR-juu0lTyRbrWYU80DOuj2hgq8LZAckkcn4Y9OwD31V-HZ3D7O-UWuVCSrsSl1LwfEu3KoJCKfKMb44FocxuN_el44nvQ0TCPFUhjRwqaRw8N6Yq5LfmwYhltBd7zWrkVW-lHMuW1M8uDzlnmbI0es6bebFl2z1VFb3XZTLG55NTWRWdScv3NmKI3oneWPbA9y5LwIvVnYZIm0SyJozjw2IFlk3R64QczPwqSaThNokeP_T7h_YtZOgniII7SeBIHaRp6DIV0xi7aaXoaqo__ABPOsUY?type=png">

## ğŸ¨ FonctionnalitÃ©s principales

âœ… **function.py** 



## ğŸ—ºï¸ Estimation de position : Ã‰tat de l'art
Pour estimer la position d'un point mobile sur une carte en utilisant les distances et angles relatifs aux bÃ¢timents environnants, plusieurs mÃ©thodes de localisation peuvent Ãªtre envisagÃ©es. Voici quelques-unes des approches pertinentes :

<p align="justify">
  
**1. Triangulation**
<p align="justify">
</p>
La triangulation est une mÃ©thode qui utilise les angles mesurÃ©s entre le point mobile et des repÃ¨res fixes (ici, les bÃ¢timents, routes, etc) pour dÃ©terminer la position. En connaissant les positions des bÃ¢timents sur la carte et les angles sous lesquels ils sont observÃ©s depuis le point mobile, il est possible de tracer des lignes de visÃ©e dont l'intersection indique la position estimÃ©e du point mobile.
<p align="justify">
</p>

**2. TrilatÃ©ration**
<p align="justify">
</p>
La trilatÃ©ration repose sur la mesure des distances entre le point mobile et au moins trois repÃ¨res connus. En traÃ§ant des cercles centrÃ©s sur chaque bÃ¢timent avec un rayon correspondant Ã  la distance mesurÃ©e, l'intersection de ces cercles fournit la position estimÃ©e du point mobile.
<p align="justify">
</p>
  
**3. Filtrage particulaire**
<p align="justify">
</p>
Le filtrage particulaire est une mÃ©thode probabiliste qui utilise un ensemble de "particules" pour reprÃ©senter des hypothÃ¨ses sur la position du point mobile. Chaque particule est pondÃ©rÃ©e en fonction de la correspondance entre les mesures (distances et angles) et les positions possibles sur la carte. Cette mÃ©thode permet de gÃ©rer les incertitudes et le bruit dans les mesures, offrant ainsi une estimation plus robuste de la position.
<p align="justify">
</p>

**4. Algorithmes de correspondance avec la carte (Map Matching)**
<p align="justify">
</p>
Cette approche consiste Ã  ajuster l'estimation de la position en comparant les observations (distances et angles par rapport aux bÃ¢timents) avec une carte dÃ©taillÃ©e de l'environnement. En identifiant les correspondances les plus probables entre les observations et les Ã©lÃ©ments de la carte, il est possible de raffiner l'estimation de la position du point mobile.
<p align="justify">
</p>

**5. SLAM (Simultaneous Localization and Mapping)**
<p align="justify">
</p>
Le SLAM est une mÃ©thode permettant de se localiser tout en construisant simultanÃ©ment une carte de son environnement inconnu. Cette technique est couramment utilisÃ©e en robotique mobile pour naviguer sans GPS ni repÃ¨res prÃ©alablement identifiÃ©s.


## ğŸ—ºï¸ Estimation de position : Solution retenue

Un algorithme de Map Matching m'a semblÃ© Ãªtre une bonne solution dans un premier temps. En effet le fait de reconstruire une carte au fur et Ã  mesure dans le cas du SLAM ne me parait pas nÃ©cessaire Ã©tant donnÃ© que l'on possÃ¨de dÃ©jÃ  une carte connue en mÃ©moire. Quand Ã  aux mÃ©thodes de triangulation et trilatÃ©ration, elles ne me semblent pas rÃ©alisable dans notre cas puisqu'on aurait besoin d'identifier des points prÃ©cis (bÃ¢timents spÃ©cifique, point de repÃ¨re, etc), et notre dÃ©tection d'image ne nous permettra probablement pas d'identifier des bÃ¢timents spÃ©cifiques. (On aura probablement seulement des labels "batiments", "route", "riviÃ¨re", etc.)

AprÃ¨s rÃ©flÃ©xion, voici un pseudo-code de l'algorithme de map matching que je souhaite rÃ©alisÃ© : 

```python
def map_matching(observations, map_objects, position_prev, search_radius):
    best_position = None
    best_score = float('inf')

    # GÃ©nÃ©rer des positions candidates autour de la position prÃ©cÃ©dente
    candidate_positions = generate_positions(position_prev, search_radius)

    for position in candidate_positions:
        score = 0
        
        for obs in observations:  # Parcours des objets observÃ©s
            x_obs = position.x + obs.distance * cos(obs.angle)
            y_obs = position.y + obs.distance * sin(obs.angle)

            # Rechercher les objets correspondants dans la carte
            candidates = filter_map_objects(map_objects, obs.label)
            nearest_object = find_nearest_object(candidates, x_obs, y_obs)

            # Calculer l'erreur
            dist_error = abs(obs.distance - compute_distance(position, nearest_object))
            angle_error = abs(obs.angle - compute_angle(position, nearest_object))

            # Additionner les erreurs pondÃ©rÃ©es
            score += weight_distance * dist_error + weight_angle * angle_error
        
        # Mettre Ã  jour la meilleure position
        if score < best_score:
            best_score = score
            best_position = position

    return best_position
```

Ce que l'on veut rÃ©aliser avec cet algorithme : 

**- GÃ©nÃ©ration de positions candidates** : Autour de la position prÃ©cÃ©dente ou dans une zone de recherche dÃ©finie. Typiquement on peut imaginer un filtre de kalman nous permettant de calculer une ellipse autour du point prÃ©cÃ©dent, reprÃ©sentant les diffÃ©rentes positions possible pour notre point mobile. Dans cette ellipse on pourra alors choisir des points (les plus probables dans un premier temps) pour les comparer Ã  notre point actuel (mais inconnu, on a Ã  ce moment seulement l'observation depuis notre point)

**- Projection des observations sur la carte globale** :

Pour chaque objet observÃ© (distance dkâ€‹, angle Î¸kâ€‹, label Lkâ€‹) autour du point mobile :

Calcul des coordonnÃ©es relatives : 
Ã€ partir de l'observation locale, calculez les coordonnÃ©es de l'objet autour du point mobile supposÃ© (xt,yt) :
xk'= xt + dkâ‹…cosâ¡(Î¸k)
yk'= yt â€‹+ dkâ€‹â‹…sin(Î¸kâ€‹)

oÃ¹ (xk', yk') sont les coordonnÃ©es estimÃ©es de l'objet dans la carte globale.

Filtrage des objets candidats :
    En parcourant le tableaux des objets de la carte globale on sÃ©lectionne les objets dont le label correspond      Ã  Lkâ€‹ (par exemple "bÃ¢timent") et dont la distance par rapport Ã  (xkâ€²,ykâ€²)est minimale
 
**- Ã‰valuation du score** : Le score mesure l'erreur entre les observations (distance et angle) et les positions rÃ©elles des objets sur la carte. Ici on pourra imaginer plusieurs faÃ§on de calculer le score. Par exemple on peut pondÃ©rer le score en fonction de la distance. i.e. plus l'objet est loin moins il affecte l'erreur affecte le score. A voir.

**- Optimisation** : SÃ©lection de la position qui minimise l'erreur globale. On estime donc que c'est notre position actuelle. On peut alors dÃ©cider en consÃ©quence des actions Ã  faire pour aller vers notre destination.


## Outils nÃ©cessaires : OSMnx, shapely

Pour rÃ©aliser ce projet on a donc besoin de trouver un moyen de stocker les informations d'une carte symbolique et des objets prÃ©sents sur la carte. (BÃ¢timent, route, etc)

Les cartes vectorielles m'ont semblÃ©es Ãªtre le meilleurs moyen d'avoir toutes ces informations Ã  disposition pour avoir Ã  la fois une certaine facilitÃ© Ã  manipulÃ© les coordonÃ©es, calculs de distance et angle et de pouvoir les visualiser relativement facilement. 

C'est lÃ  qu'intervient OSMnx, c'est une bibliothÃ¨que Python permettant de tÃ©lÃ©charger, manipuler et analyser les donnÃ©es gÃ©ospatiales issues d'OpenStreetMap (OSM). C'est particuliÃ¨rement utile pour :

- RÃ©cupÃ©rer des rÃ©seaux routiers, bÃ¢timents et infrastructures sous forme de graphiques ou de GeoDataFrames.
- GÃ©nÃ©rer et manipuler des cartes vectorielles.
- Effectuer des calculs gÃ©ographiques tels que la distance entre objets, le routage, ou encore l'analyse des environnements urbains.

La fonction ci-dessus permet de tÃ©lÃ©charger une carte vectorielle avec les objets souhaitÃ©s, autour d'un point de coordonnÃ©e donnÃ© (lat, lon), dans un carrÃ©e de cotÃ© (dist): 

```python
def gen_vect_map(lat, lon, dist):
    """
    GÃ©nÃ¨re les donnÃ©es vectorielles OSM pour une zone autour d'un point central.

    Args:
        lat (float): Latitude du centre.
        lon (float): Longitude du centre.
        dist (int): Distance en mÃ¨tres entre le centre et les bords de la zone.

    Returns:
        gdf (GeoDataFrame): DonnÃ©es vectorielles OSM avec types d'objets.
        bbox (tuple): Limites (north, south, east, west) de la zone.
    """

    # DÃ©finir un point central (lat, lon) et une zone de 2*dist x 2*dist autour du point
    center_lat, center_lon = lat, lon
    distance = dist  # distance entre le point central et les cÃ´tÃ©s (donc bord_map = 2 * dist)

    north, south, east, west = ox.utils_geo.bbox_from_point((center_lat, center_lon), dist=distance)

    # DÃ©finir les tags pour rÃ©cupÃ©rer plusieurs types d'Ã©lÃ©ments
    tags = {
        'building': True,  # Tous les bÃ¢timents
        'highway': True,  # Toutes les routes et chemins
        #'waterway': True,  # Toutes les riviÃ¨res et canaux
        #'natural': ['water', 'wood'],  # Ã‰lÃ©ments naturels (eau)
        #'landuse': 'forest',  # Zones de forÃªt
        #'amenity': ['school', 'hospital', 'restaurant'],  # Ã‰coles, hÃ´pitaux et restaurants
        #'leisure': 'park',  # Parcs de loisirs
        #'tourism': 'hotel',  # HÃ´tels
        #'railway': 'station'  # Stations ferroviaires
    }

    # TÃ©lÃ©charger les donnÃ©es dans cette zone
    gdf = ox.geometries_from_bbox(north, south, east, west, tags)

    # Ajouter une colonne indiquant le type d'objet
    def get_object_type(row):
        for tag in ['building', 'highway', 'waterway']:
            if tag in row and not pd.isna(row[tag]):
                return tag
        return "unknown"

    gdf['object_type'] = gdf.apply(get_object_type, axis=1)

    return gdf, (north, south, east, west)
```

Avec la fonction "plot_vect_map" on obtient alors l'affichage suivant : 

![image](https://github.com/user-attachments/assets/7e3e1b06-dae0-4e58-8b0b-c02b5c638217)
![image](https://github.com/user-attachments/assets/93ba71f2-cd03-46f8-9c68-d4ad3efff411)

Afin de pouvoir ensuite faire le calcul pour faire le map matching on doit calculer la distance et l'angle relatif Ã  notre point mobile. On rÃ©alise cette Ã©tape avec le code ci-dessous.
(Afin de conserver ces donnÃ©es on les enregistre dans le geodataframe de la carte.)

```python
def calculate_distances_and_angles(gdf, bbox):
    """
    Calcule les distances et angles relatifs des objets par rapport au centroÃ¯de global de la carte.

    Args:
        gdf (GeoDataFrame): Objets gÃ©ographiques.

    Returns:
        GeoDataFrame: Objets avec distances et angles relatifs ajoutÃ©s.
        tuple: (lat, lon) du centre calculÃ©.
        DataFrame: Tableau des labels, distances et angles pour chaque objet.
    """
    # Calculer la position centrale de la carte
    north, south, east, west = bbox  # RÃ©cupÃ©rer les limites
    center_lat = (north + south) / 2
    center_lon = (east + west) / 2

    # Initialiser un gÃ©odÃ©sique pour les calculs
    geod = Geod(ellps="WGS84")

    # Calculer la distance et l'angle
    def compute_distance_and_angle(row):
        obj_x, obj_y = row.geometry.centroid.xy
        obj_lon, obj_lat = obj_x[0], obj_y[0]

        # Distance en mÃ¨tres
        _, _, distance = geod.inv(center_lon, center_lat, obj_lon, obj_lat)

        # Angle relatif
        dx = obj_lon - center_lon
        dy = obj_lat - center_lat
        angle = degrees(atan2(dy, dx)) % 360  # Angle en [0, 360]

        return pd.Series({'distance_m': distance, 'angle_deg': angle})

    # Appliquer les calculs
    gdf[['distance_m', 'angle_deg']] = gdf.apply(compute_distance_and_angle, axis=1)

    # CrÃ©er un tableau avec les labels, distances et angles
    table = gdf[['object_type', 'distance_m', 'angle_deg']].reset_index(drop=True)

    return gdf, (center_lat, center_lon), table
```

On obtient alors le rÃ©sultat suivant Ã  la visualisation : 
(ici on part du principe que notre drone est au centre de l'observation, on place donc un point au centre de notre bbox et on calcul les distances et les angles relatif Ã  ce point)
![image](https://github.com/user-attachments/assets/b9330c79-4d7c-44bb-9ac8-75af48f045fb)

Pour pouvoir rÃ©aliser le map matching on doit aussi rÃ©aliser cette Ã©tape sur la carte connue Ã  partir du point estimÃ©. (Dans un premier temps on utilise le mÃªme point que notre point d'observation)
![image](https://github.com/user-attachments/assets/01af5f89-056c-42e0-b9e5-529ada203ace)


## CrÃ©ation de map vectorielle

Dans ce projet, aprÃ¨s la reconnaissance d'image il nous sera certainement utile de crÃ©er notre propre carte vectorielle pour ensuite pouvoir la comparer Ã  notre carte connue. Pour rÃ©aliser cette Ã©tape on ne pourra donc pas se reposer sur OSMnx pour tÃ©lÃ©charger un Geodataframe, on devra le crÃ©er nous mÃªme. 
Plusieurs faÃ§on sont possible, mais ici nous avons utiliser la bibliothÃ¨que Shapely.

Le code ci-dessous est une preuve de concept montrant que l'on peut crÃ©er notre propre carte vectorielle afin de reprÃ©senter notre observation dans la suite du projet. 

```python
from shapely.geometry import Polygon, LineString
from shapely.geometry import Point
import geopandas as gpd
import matplotlib.pyplot as plt
import numpy as np

# DÃ©finir les gÃ©omÃ©tries des bÃ¢timents, de la route et de la riviÃ¨re
building1 = Polygon([(20, 20), (40, 20), (40, 50), (20, 50), (20, 20)])
building2 = Polygon([(60, 60), (80, 60), (80, 90), (60, 90), (60, 60)])
#building3 = Polygon([(120, 20), (140, 20), (140, 50), (120, 50), (120, 20)])
building4 = Polygon([(160, 160), (180, 160), (180, 180), (160, 180), (160, 160)])

road1 = LineString([(0, 100), (200, 100)])
road2 = LineString([(100, 0), (100, 200)])

# GÃ©nÃ©rer une riviÃ¨re avec de vraies courbes
x = np.linspace(0, 200, 100)
y = 50 + 2 * np.sin(x / 30)  # Fonction sinus pour des courbes naturelles
river_points = [Point(x[i], y[i]) for i in range(len(x))]
river = LineString(river_points)

# Convertir les gÃ©omÃ©tries en GeoDataFrames
buildings = gpd.GeoDataFrame(
    {'name': ['Building 1', 'Building 2', 'Building 4'],
     'geometry': [building1, building2, building4]},
    crs="EPSG:4326"
)

roads = gpd.GeoDataFrame(
    {'name': ['Road 1', 'Road 2'],
     'geometry': [road1, road2]},
    crs="EPSG:4326"
)

rivers = gpd.GeoDataFrame(
    {'name': ['River'],
     'geometry': [river]},
    crs="EPSG:4326"
)

# Visualisation
fig, ax = plt.subplots(figsize=(10, 10))

# Tracer chaque couche sur la carte
buildings.plot(ax=ax, color='gray', edgecolor='black', label='Buildings')
roads.plot(ax=ax, color='black', linewidth=2, label='Roads')
rivers.plot(ax=ax, color='blue', linewidth=2, linestyle='--', label='River')

# Ajouter une lÃ©gende et des Ã©tiquettes
ax.legend()
ax.set_title("Map with Buildings, Roads, and River")
ax.set_xlim(0, 200)
ax.set_ylim(0, 200)
ax.set_xlabel("")
ax.set_ylabel("")

# Afficher la carte
plt.show()
```

<img src="https://github.com/user-attachments/assets/71819bbd-0f8c-4482-8f9a-c2acab31f270" width="50%" height="50%">

## ğŸ”— Liens utiles

- ğŸ“ [Ensta Bretagne](https://www.ensta-bretagne.fr/fr)
- ğŸ–‡ï¸ [Github BinÃ´me](https://github.com/RD-ENSTA/Navigation-drone-sans-GPS)
- ğŸ“‘ [Documentation OSMnx](https://osmnx.readthedocs.io/en/stable/)
- ğŸ“‘ [Documentation Shapely](https://shapely.readthedocs.io/en/2.0.4/manual.html)


## ğŸ“œ Licence

Ce projet est sous licence **MIT**. Voir le fichier [LICENSE](LICENSE) pour plus d'informations.

---
